{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Carga de datos y preprocesamiento de datos"
      ],
      "metadata": {
        "id": "XxkWMu3NJ-zr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carga de datos"
      ],
      "metadata": {
        "id": "9Gtv1mH0KJp6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byHzu4mC_v5z",
        "outputId": "fc9cba2a-a68d-4c88-f3f7-73973e2898c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset\n",
            "       destination  passanger weather  temperature  time  \\\n",
            "0  No Urgent Place      Alone   Sunny           55   2PM   \n",
            "1  No Urgent Place  Friend(s)   Sunny           80  10AM   \n",
            "2  No Urgent Place  Friend(s)   Sunny           80  10AM   \n",
            "3  No Urgent Place  Friend(s)   Sunny           80   2PM   \n",
            "4  No Urgent Place  Friend(s)   Sunny           80   2PM   \n",
            "\n",
            "                  coupon expiration  gender age      maritalStatus  ...  \\\n",
            "0        Restaurant(<20)         1d  Female  21  Unmarried partner  ...   \n",
            "1           Coffee House         2h  Female  21  Unmarried partner  ...   \n",
            "2  Carry out & Take away         2h  Female  21  Unmarried partner  ...   \n",
            "3           Coffee House         2h  Female  21  Unmarried partner  ...   \n",
            "4           Coffee House         1d  Female  21  Unmarried partner  ...   \n",
            "\n",
            "   CoffeeHouse CarryAway RestaurantLessThan20 Restaurant20To50  \\\n",
            "0        never       NaN                  4~8              1~3   \n",
            "1        never       NaN                  4~8              1~3   \n",
            "2        never       NaN                  4~8              1~3   \n",
            "3        never       NaN                  4~8              1~3   \n",
            "4        never       NaN                  4~8              1~3   \n",
            "\n",
            "  toCoupon_GEQ5min toCoupon_GEQ15min toCoupon_GEQ25min direction_same  \\\n",
            "0                1                 0                 0              0   \n",
            "1                1                 0                 0              0   \n",
            "2                1                 1                 0              0   \n",
            "3                1                 1                 0              0   \n",
            "4                1                 1                 0              0   \n",
            "\n",
            "  direction_opp  Y  \n",
            "0             1  1  \n",
            "1             1  0  \n",
            "2             1  1  \n",
            "3             1  0  \n",
            "4             1  0  \n",
            "\n",
            "[5 rows x 26 columns]\n",
            "Numero de muestras: 12684\n",
            "Numero de atributos 26\n",
            "Tipos de atributos destination             object\n",
            "passanger               object\n",
            "weather                 object\n",
            "temperature              int64\n",
            "time                    object\n",
            "coupon                  object\n",
            "expiration              object\n",
            "gender                  object\n",
            "age                     object\n",
            "maritalStatus           object\n",
            "has_children             int64\n",
            "education               object\n",
            "occupation              object\n",
            "income                  object\n",
            "car                     object\n",
            "Bar                     object\n",
            "CoffeeHouse             object\n",
            "CarryAway               object\n",
            "RestaurantLessThan20    object\n",
            "Restaurant20To50        object\n",
            "toCoupon_GEQ5min         int64\n",
            "toCoupon_GEQ15min        int64\n",
            "toCoupon_GEQ25min        int64\n",
            "direction_same           int64\n",
            "direction_opp            int64\n",
            "Y                        int64\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from typing import cast\n",
        "\n",
        "\n",
        "dataset_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00603/in-vehicle-coupon-recommendation.csv\"\n",
        "\n",
        "# Cargamos el dataset\n",
        "dataset = pd.read_csv(dataset_url)\n",
        "\n",
        "print(\"Dataset\")\n",
        "print(dataset.head())\n",
        "\n",
        "# Metricas basicas del dataset\n",
        "print(\"Numero de muestras:\", dataset.shape[0])\n",
        "print(\"Numero de atributos\", dataset.shape[1])\n",
        "print(\"Tipos de atributos\", dataset.dtypes)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Análisis de dataset"
      ],
      "metadata": {
        "id": "ovdHBEAKKaCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Analisis del dataset\n",
        "\n",
        "# Calculamos el porcentaje de valores faltantes\n",
        "missing_values = 100 * dataset.isna().sum() / len(dataset)\n",
        "\n",
        "print(\"Valores faltantes\")\n",
        "print(missing_values)\n",
        "\n",
        "# Calculamos la matrix de correlacion de nuestro dataset\n",
        "corr = dataset.corr(numeric_only=True)\n",
        "\n",
        "print(\"Matriz de correlacion\")\n",
        "print(corr)\n",
        "\n"
      ],
      "metadata": {
        "id": "UGYBg4BjDaz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocesamiento de datos"
      ],
      "metadata": {
        "id": "fN1CbO4TKhLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocesamiento\n",
        "\n",
        "# Eliminamos muestras duplicadas\n",
        "dataset.drop_duplicates(inplace=True)\n",
        "\n",
        "# Eliminamos los atributos 'car', 'direction_opp' y 'toCoupon_GEQ5min'\n",
        "dataset.drop(columns=[\"car\", \"direction_opp\",\n",
        "             \"toCoupon_GEQ5min\"], inplace=True)\n",
        "\n",
        "# Completamos los valores faltantes usando la moda de cada atributo\n",
        "missing_values = cast(pd.Series, dataset.isna().sum())\n",
        "missing_values = cast(pd.Series, missing_values[missing_values > 0])\n",
        "\n",
        "for column in missing_values.to_dict():\n",
        "    mode = dataset[column].value_counts().index[0]\n",
        "    dataset[column].fillna(mode, inplace=True)\n",
        "\n",
        "print(\"Existen valores faltantes?\", dataset.isna().values.any())\n",
        "\n"
      ],
      "metadata": {
        "id": "qQXLQAx0DeQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encodificación"
      ],
      "metadata": {
        "id": "gGDCWwSfKkxm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ingenieria de atributos\n",
        "dataset[\"is_unemployed\"] = dataset[\"occupation\"].map(\n",
        "    lambda o: 1 if o == \"Unemployed\" else 0)\n",
        "\n",
        "dataset[\"is_student\"] = dataset[\"occupation\"].map(\n",
        "    lambda o: 1 if o == \"Student\" else 0)\n",
        "\n",
        "dataset.drop(columns=[\"occupation\"], inplace=True)\n",
        "\n",
        "# One hot encoding\n",
        "categorical_columns = dataset.dtypes[dataset.dtypes ==\n",
        "                                     \"object\"].index.to_list()\n",
        "\n",
        "for column in categorical_columns:\n",
        "    encoded = pd.get_dummies(dataset[column], prefix=column, dtype=int)\n",
        "    dataset.drop(columns=[column], inplace=True)\n",
        "    dataset = dataset.join(encoded)\n",
        "\n",
        "# Guardamos el dataset preprocesado\n",
        "#dataset.to_csv(\"in-vehicle-coupon-recommendation-processed.csv\", index=False)"
      ],
      "metadata": {
        "id": "9q-rdf35DhQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "División del Dataset"
      ],
      "metadata": {
        "id": "Fbl_Ia2iRzYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Separamos la data, en variables independientes (x) y dependientes (y), para poder entrenar un árbol de clasificación\n",
        "x = dataset.drop([\"Y\"], axis=1)\n",
        "\n",
        "y = dataset[\"Y\"]"
      ],
      "metadata": {
        "id": "tCWG2yGJSx7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Mediante el método \"train_test_split\" usaremos el 20% de la data para probar el modelo. El parámetro \"random state\" nos sirve para\n",
        "#poder replicar la misma separación\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "zw6moKhFR17i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Entrenamiento de Modelos"
      ],
      "metadata": {
        "id": "HkTASPz0NTTf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear Regresion"
      ],
      "metadata": {
        "id": "UYvUALu_RYut"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GoVupFt9RJgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest"
      ],
      "metadata": {
        "id": "j3U9Hqt2X9dp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TRIeCnPlYBFb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}